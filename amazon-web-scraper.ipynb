{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b516711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS  --RUN THIS\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define get_xx methods on product listing page   --RUN THIS\n",
    "\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"span\", attrs={\"id\": 'productTitle'})\n",
    "        \n",
    "        title_string = title.text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "        \n",
    "    return title_string\n",
    "\n",
    "def get_original_price(soup):\n",
    "\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'class':'a-size-small a-color-secondary aok-align-center basisPrice'}).find(\"span\", attrs={'class':'a-offscreen'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "\n",
    "        price = \"\"\n",
    "\n",
    "    return price\n",
    "\n",
    "def get_sale_price(soup):\n",
    "    \n",
    "    try:\n",
    "        price_desc = soup.find(\"div\", attrs={'class':'a-section a-spacing-none aok-align-center aok-relative'}).find(\"span\", attrs={\"aok-offscreen\"}).text.strip().split(\" \")\n",
    "        price = price_desc[0]\n",
    "        if len(price_desc) > 2:\n",
    "            \n",
    "            discount = price_desc[2]\n",
    "        else:\n",
    "            discount = \"\"\n",
    "        \n",
    "    except AttributeError:\n",
    "\n",
    "        price = \"\"\n",
    "        discount = \"\"\n",
    "        \n",
    "    return price, discount\n",
    "\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = soup.find(\"div\", attrs={'id':'averageCustomerReviews'}).find(\"span\", attrs={'class': 'a-size-base a-color-base'}).string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\n",
    "            \n",
    "    if \"Previous page\" in rating:\n",
    "        rating = \"\"\n",
    "        \n",
    "    return rating\n",
    "\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip().split(\" \")[0]\n",
    "\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\n",
    "\n",
    "    return review_count\n",
    "\n",
    "def get_categories(soup):\n",
    "\n",
    "    def extract_category(text):\n",
    "        word_pos = text.find(\"in\")\n",
    "        if word_pos != -1:\n",
    "            # Slicing after the word\n",
    "            return text[word_pos + 2:].strip()\n",
    "        return text.strip()\n",
    "        \n",
    "    try:\n",
    "        product_details = soup.find(\"div\", attrs={'id':'detailBulletsWrapper_feature_div'}).find_all(\"span\", attrs={'class':'a-list-item'})\n",
    "        ranks = \"\"\n",
    "        for prod in product_details:\n",
    "            text = prod.text.strip()\n",
    "            if 'Best Sellers Rank' in text:\n",
    "                ranks = prod\n",
    "                break\n",
    "        ranking = ranks.find_all(\"a\")\n",
    "        cat1 = extract_category(ranking[0].text)\n",
    "        cat2 = ranking[-1].text.strip()\n",
    "        \n",
    "        \n",
    "    except AttributeError:\n",
    "       \n",
    "        try:\n",
    "            product_details = soup.find(\"div\", attrs={'id': 'prodDetails'}).find_all(\"tr\")\n",
    "            ranks = \"\"\n",
    "            for prod in product_details:\n",
    "                text = prod.find(\"th\", attrs={'class':'a-color-secondary a-size-base prodDetSectionEntry'}).text.strip()\n",
    "                if 'Best Sellers Rank' in text:\n",
    "                    ranks = prod\n",
    "                    break\n",
    "            ranking = ranks.find_all(\"a\")\n",
    "            cat1 = extract_category(ranking[0].text)\n",
    "            cat2 = ranking[-1].text.strip()\n",
    "                    \n",
    "\n",
    "        except AttributeError:\n",
    "            cat1 = \"\"\n",
    "            cat2 = \"\"\n",
    "            \n",
    "    return cat1, cat2\n",
    "\n",
    "def get_rankings(soup):\n",
    "    try:\n",
    "        product_details = soup.find(\"div\", attrs={'id':'detailBulletsWrapper_feature_div'}).find_all(\"span\", attrs={'class':'a-list-item'})\n",
    "        ranks = \"\"\n",
    "        for prod in product_details:\n",
    "            text = prod.text.strip()\n",
    "            if 'Best Sellers Rank' in text:\n",
    "                ranks = prod\n",
    "                break\n",
    "        ranking = ranks.text[20:].strip()\n",
    "        \n",
    "        \n",
    "    except AttributeError:\n",
    "       \n",
    "        try:\n",
    "            product_details = soup.find(\"div\", attrs={'id': 'prodDetails'}).find_all(\"tr\")\n",
    "            ranks = \"\"\n",
    "            for prod in product_details:\n",
    "                text = prod.find(\"th\", attrs={'class':'a-color-secondary a-size-base prodDetSectionEntry'}).text.strip()\n",
    "                if 'Best Sellers Rank' in text:\n",
    "                    ranks = prod\n",
    "                    break\n",
    "            ranking = ranks.text.strip()[20:].strip()\n",
    "                    \n",
    "\n",
    "        except AttributeError:\n",
    "            ranking = \"\"\n",
    "            \n",
    "    return ranking\n",
    "\n",
    "def get_purchase_count_last_month(soup):\n",
    "    try:\n",
    "        count = soup.find(\"span\", attrs={'id':'social-proofing-faceout-title-tk_bought'}).find(\"span\").string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        count = \"\"\n",
    "    \n",
    "    return count\n",
    "\n",
    "def get_description(soup):\n",
    "    try:\n",
    "        desc_list = soup.find(\"div\", attrs={'id':'feature-bullets'}).find_all(\"span\")\n",
    "        res = []\n",
    "        for desc in desc_list:\n",
    "            res.append(desc.string.strip())\n",
    "\n",
    "        return res\n",
    "        \n",
    "    except AttributeError:\n",
    "        desc = \"\"\n",
    "        return desc\n",
    "\n",
    "def get_review_insights(soup):\n",
    "    try:\n",
    "        insights = soup.find(\"div\", attrs={'data-hook':'cr-insights-widget-aspects'}).find_all(\"button\")\n",
    "        for i in range(len(insights)):\n",
    "            insights[i] = insights[i].get('data-csa-c-item-id')\n",
    "\n",
    "    except AttributeError:\n",
    "        insights = \"\"\n",
    "\n",
    "    return insights\n",
    "\n",
    "def get_store_name(soup):\n",
    "    try:\n",
    "        store_name = soup.find(\"a\", attrs={'id':'bylineInfo'}).string.strip()\n",
    "        if \"Brand: \" in store_name:\n",
    "            store_name = store_name.replace(\"Brand: \", \"\")\n",
    "        elif \"Visit the \" in store_name:\n",
    "            store_name = store_name.replace(\"Visit the \", \"\")\n",
    "    except AttributeError:\n",
    "        store_name = \"\"\n",
    "\n",
    "    return store_name\n",
    "\n",
    "def get_supplier(soup):\n",
    "    try:\n",
    "        supplier_name = soup.find(\"a\", attrs={'id':'sellerProfileTriggerId'}).string.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        supplier_name = \"\"\n",
    "\n",
    "    return supplier_name\n",
    "\n",
    "\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"div\", attrs={'id':'availability'}).find(\"span\").string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\t\n",
    "\n",
    "    return available\n",
    "\n",
    "# def get_shipping_locations(soup):\n",
    "#     try:\n",
    "#         location = soup.find(\"div\", attrs={'class':'a-popover a-popover-modal a-declarative'})\n",
    "\n",
    "#     except AttributeError:\n",
    "#         location = \"\"\n",
    "        \n",
    "#     return location\n",
    "\n",
    "# def get_delivery_time(soup):\n",
    "#     # try:\n",
    "        \n",
    "\n",
    "#     # except AttributeError:\n",
    "#     return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f099ae-82ca-4d83-9275-869e9715675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_headers(file_name):\n",
    "    with open(file_name, \"r\") as file:\n",
    "        headers_list = [ast.literal_eval(line.strip()) for line in file]\n",
    "    return headers_list\n",
    "\n",
    "# Define a function to save data to CSV\n",
    "def save_to_csv(data, file_name):\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df['title'].replace('', np.nan, inplace=True)\n",
    "    df.to_csv(file_name, mode='a', header=not pd.io.common.file_exists(file_name), index=False)\n",
    "    print(\"SAVED TO CSV\")\n",
    "\n",
    "\n",
    "# Load headers\n",
    "HEADERS_LIST = load_headers(\"headers.txt\")\n",
    "\n",
    "# Connect to website and pull data\n",
    "start_time = time.time()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    NUM_ITEMS = 5000 # DECLARE HOW MANY ROWS YOU WANT\n",
    "    MAIN_CATEGORY = \"Boy's Fashion\" # INPUT THE CATEGORY YOU ARE SCRAPING. THIS IS WILL BE THE MAIN CATEGORY.\n",
    "    \n",
    "    URLS = []\n",
    "    BOYS_FASHION_URL = 'https://www.amazon.com/s?i=fashion-boys-intl-ship&bbn=16225021011&rh=n%3A7141123011%2Cn%3A16225021011%2Cn%3A7147443011%2Cp_n_size_six_browse-vebin%3A4940401011&dc&ds=v1%3Aea9Nn8gVro9WrRJD1zLQrqASGRn9CcdrQy45VoGcq7o&fst=as%3Aoff&pf_rd_i=16225021011&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=d84623b2-8aff-40df-9701-224067aef31e&pf_rd_r=RH2FKA9CSFGZCAXT2SV4&pf_rd_s=merchandised-search-3&pf_rd_t=101&qid=1718713695&ref=sr_ex_n_1'\n",
    "    URLS.append(BOYS_FASHION_URL)\n",
    "\n",
    "    product_listing_page = requests.get(URLS[0], headers=random.choice(HEADERS_LIST))\n",
    "    soup = BeautifulSoup(product_listing_page.content, \"html.parser\")\n",
    "    product_links = soup.find_all(\"a\", attrs={'class': 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "    \n",
    "    product_links_list = []\n",
    "    for link in product_links:\n",
    "        product_links_list.append(link.get('href'))\n",
    "\n",
    "    data = {\"title\": [], \"original_price\": [], \"sale_price\": [], \"discount\": [], \"rating\": [], \"review_count\": [], \"main_category\": [], \"sub_category_1\": [], \"sub_category_2\": [], \"rankings\": [], \"description\": [], \"insights\": [], \"purchase_cnt_prev_month\": [], \"store_name\": [], \"supplier\": [], \"is_available\": [], \"url\": []}\n",
    "    CSV_FILE_NAME = 'Boys Fashion' + '.csv' # INPUT YOUR CSV FILE NAME\n",
    "    \n",
    "    i = 0\n",
    "    page = 327\n",
    "    while (i <= NUM_ITEMS):\n",
    "        for link in product_links_list:\n",
    "            try:\n",
    "                product_webpage = requests.get(\"https://www.amazon.com\" + link, headers=random.choice(HEADERS_LIST))\n",
    "                \n",
    "            except OSError:\n",
    "                continue\n",
    "            except AttributeError as e:\n",
    "                print(f\"Encountered an AttributeError: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Encountered an error: {e}\")\n",
    "                continue\n",
    "                \n",
    "            product_soup = BeautifulSoup(product_webpage.content, \"html.parser\")\n",
    "            sale_price, discount = get_sale_price(product_soup)\n",
    "            if sale_price == \"\":\n",
    "                continue\n",
    "            data['title'].append(get_title(product_soup))\n",
    "            data['original_price'].append(get_original_price(product_soup))\n",
    "            data['sale_price'].append(sale_price)\n",
    "            data['discount'].append(discount)\n",
    "            data['rating'].append(get_rating(product_soup))\n",
    "            data['review_count'].append(get_review_count(product_soup))\n",
    "            data['main_category'].append(MAIN_CATEGORY)\n",
    "            cat1, cat2 = get_categories(product_soup)\n",
    "            data['sub_category_1'].append(cat1)\n",
    "            data['sub_category_2'].append(cat2)\n",
    "            data['rankings'].append(get_rankings(product_soup))\n",
    "            data['description'].append(get_description(product_soup))\n",
    "            data['insights'].append(get_review_insights(product_soup))\n",
    "            data['purchase_cnt_prev_month'].append(get_purchase_count_last_month(product_soup))\n",
    "            data['store_name'].append(get_store_name(product_soup))\n",
    "            data['supplier'].append(get_supplier(product_soup))\n",
    "            data['is_available'].append(get_availability(product_soup))\n",
    "            data['url'].append(link)\n",
    "        \n",
    "            print(f\"retrieved listing {i}\")\n",
    "            time.sleep(random.randint(1, 2))\n",
    "            i += 1\n",
    "            \n",
    "            # Save to CSV every 100 items\n",
    "            if i % 100 == 0:\n",
    "                save_to_csv(data, CSV_FILE_NAME)\n",
    "                data = {key: [] for key in data}  # Reset the data dictionary\n",
    "        \n",
    "        # navigate to next page if more items are needed\n",
    "        if len(data) < NUM_ITEMS:\n",
    "            try:\n",
    "                next_page_element = soup.find(\"a\", attrs={'class': 's-pagination-item s-pagination-next s-pagination-button s-pagination-separator'})\n",
    "                if next_page_element:\n",
    "                    next_page_suffix = next_page_element.get('href')\n",
    "                    next_webpage = requests.get(\"https://www.amazon.com\" + next_page_suffix, headers=random.choice(HEADERS_LIST))\n",
    "                    soup = BeautifulSoup(next_webpage.content, \"html.parser\")\n",
    "                    product_links = soup.find_all(\"a\", attrs={'class': 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "\n",
    "                    product_links_list = []\n",
    "                    for link in product_links:\n",
    "                        product_links_list.append(link.get('href'))\n",
    "                    page += 1\n",
    "                    print(f\"Retrieving page {page} with {len(product_links_list)} items\")\n",
    "                else:\n",
    "                    print(\"No more pages to retrieve.\")\n",
    "                    break\n",
    "            except AttributeError as e:\n",
    "                print(f\"Encountered an AttributeError: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Encountered an error: {e}\")\n",
    "                continue\n",
    "\n",
    "    save_to_csv(data, CSV_FILE_NAME)\n",
    "    print(\"done\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time elapsed: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648c7d5-4a37-40bc-a68c-02a30e2b6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to csv\n",
    "\n",
    "# CSV_FILE_NAME = 'Womens Fashion' + '.csv' # INPUT YOUR CSV FILE NAME\n",
    "\n",
    "# amazon_df = pd.DataFrame.from_dict(data)\n",
    "# amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "# # amazon_df = amazon_df.dropna(subset=['title'])\n",
    "# amazon_df.to_csv(CSV_FILE_NAME, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636f9cc-d945-4c15-9f8e-2e1ac91f21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Womens Fashion.csv')\n",
    "\n",
    "# # Remove duplicate rows\n",
    "# df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# # Save the cleaned DataFrame back to a CSV file\n",
    "# df_cleaned.to_csv('Womens Fashion Cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d094f1-1935-49ec-a41a-2dbceffd249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK YOUR FUNCTION WORKS -- UNCOMMENT THE ONE YOU ARE TESTING\n",
    "\n",
    "# uncomment these two as well\n",
    "# product_listing_page = requests.get(\"https://www.amazon.com\" + product_links_list[3], headers=HEADERS)\n",
    "# product_listing_soup = BeautifulSoup(product_listing_page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "# product_title = get_title(product_listing_soup)\n",
    "# product_title\n",
    "\n",
    "# product_list_price = get_list_price(product_listing_soup)\n",
    "# product_list_price\n",
    "\n",
    "# product_listing_soup.find_all(\"div\", attrs={\"class\":\"a-section a-spacing-none aok-align-center aok-relative\"})\n",
    "\n",
    "# sale_price = get_sale_price(product_listing_soup)\n",
    "# print(sale_price)\n",
    "\n",
    "# rating = get_rating(product_listing_soup)\n",
    "# rating\n",
    "\n",
    "# availability = get_availability(product_listing_soup)\n",
    "# availability\n",
    "\n",
    "# store_name = get_store_name(product_listing_soup)\n",
    "# store_name\n",
    "\n",
    "# desc = get_product_description(product_listing_soup)\n",
    "# desc\n",
    "\n",
    "# ranking = get_best_sellers_rank(product_listing_soup)\n",
    "# ranking\n",
    "\n",
    "# purchase_last_month = get_purchase_count_last_month(product_listing_soup)\n",
    "# purchase_last_month\n",
    "\n",
    "# categories = get_categories(product_listing_soup)\n",
    "# categories\n",
    "\n",
    "# insights = get_review_insights(product_listing_soup)\n",
    "# insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
